class: center, middle, intro

<h1 class="text-7xl mb-0">Attacking Large Language Models</h1>
<h2 class="text-3xl mt-2">(Part 1)</h2>

<p class="text-3xl">Brandon Sprague</p>

2024-08-02

---

class: center, middle

# What are Large Language Models (LLMs)?

???

- Taking the world by storm
- When you hear people talking about "AI" today, they're usually talking about LLMs

---

# Architectures

<div class="grid grid-cols-2 -mx-8">
  <div>
    <h2 class="my-0">Transformers</h2>
    <img src="/assets/transformer.png" /img>
  </div>
  <div>
    <h2 class="my-0">SSMs</h2>
    <img src="/assets/ssm.png" class="w-1/2 mx-auto" /img>
  </div>
</div>

---

<div class="grid grid-cols-2 -mx-8 mb-4 mt-20">
  <div>
    <img src="/assets/transformer-math.png" /img>
    <a class="text-center block" href="https://en.wikipedia.org/wiki/Transformer_(deep_learning_architecture)#Sub-quadratic_transformers">Source</a>
  </div>
  <div>
    <img src="/assets/ssm-math.png" /img>
    <a class="text-center block" href="https://huggingface.co/blog/lbourdois/get-on-the-ssm-train#-recursive-view-of-an-ssm-">Source</a>
  </div>
</div>

<h1 class="text-center">Basically just a giant pile of math and computation</h1>

???

- Some compute numbers
  - GPT4 [Source](https://klu.ai/blog/gpt-4-llm)
    - 1.8T parameters
    - 13 trillion token data set
    - 25k Nvidia A100 GPUs, running for 90-100 days
      - Each GPU costs $15k
      - Compare to RTX 4090
  - Llama 3.1 405B [Source](https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md)
    - 30 million GPU hours to train
    - 15 trillion tokens
    - Facebook purchasing 350,000 H100 GPUs [Source](https://www.pcmag.com/news/zuckerbergs-meta-is-spending-billions-to-buy-350000-nvidia-h100-gpus)

---

# Why should we care about any of this?

- Because LLMs are powerful tools
  - And to use them, it's important to know their limitations
- Because they're being integrated into everything
  - And that gives plenty of opportunities for hackers to exploit them

???

- Lots of the integrations are pretty bad too

---

# Jailbreaking LLMs

- Many deployed LLM systems are 'safety-aligned' and use system prompts to limit what they can do.
- 'Jailbreaking' is about prompting an LLM such that you override their alignment + system prompts.

---

# My Favorite Example

<img class="w-[60%] mx-auto" src="/assets/jailbreak-before.png" /img>

---

# My Favorite Example

<img class="w-[60%] mx-auto" src="/assets/jailbreak-after1.png" /img>

---

# My Favorite Example

<img class="w-[80%] mx-auto" src="/assets/jailbreak-after2.png" /img>

???

- Takeaway: emotional appeals work
- If you tell an LLM that puppies and kittens will die if they don't answer your question, they're actually more likely to answer your question!
- Why does this work?
  - Models are trained on real data, and learn to behave how humans behave

---

<h1 class="mb-2">Different Jailbreaking Approaches</h1>

<img class="w-full mx-auto" src="/assets/cold-attack.png" />
<a class="text-center block" href="https://arxiv.org/abs/2402.08679">Source</a>

???

- These were actually automatically generated by another LLM tasked with breaking the target LLM.

---

<h1 class="mb-2">Another attack: exploiting internal structure</h1>

<img class="w-[88%] mx-auto" src="/assets/gcg.png" />
<a class="text-center block" href="https://arxiv.org/abs/2310.08419">Source</a>

---

<h1 class="mb-2">Harmless Example</h1>

<img class="w-[70%] mx-auto" src="/assets/chevy-tahoe.png" />

<a class="text-center block" href="https://x.com/ChrisJBakke/status/1736533308849443121">Source</a>

---

<h1 class="mb-2">Less Harmless Example</h1>

<img src="/assets/bing-pirate.png" />

<a class="text-center block" href="https://greshake.github.io/">Source</a>

???

A proof of concept where text on the page instructs the LLM to pretend to be Microsoft in an attempt to steal payment information

---

<h1 class="mb-2">Another Less Harmless Example</h1>

<img src="/assets/pentest-rce.png" />

<a class="text-center block" href="https://www.blazeinfosec.com/post/llm-pentest-agent-hacking/">Source</a>

???

If you don't integrate LLMs carefully, they can be used to exploit your infrastructure

---

class: center, middle

# Your Turn

<a class="text-4xl" href="https://cybr.lol/jailbreak" target="_blank">cybr.lol/jailbreak</a>

---

class: center, middle

# Questions?

